{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4153,"status":"ok","timestamp":1686229594599,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"_cnduYzP5lMs","outputId":"f8661ec3-9483-4553-f8e3-361eca0b6d8e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting facenet-pytorch\n","  Downloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (2.27.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (0.15.2+cu118)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (8.4.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (3.4)\n","Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision->facenet-pytorch) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision->facenet-pytorch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision->facenet-pytorch) (16.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision->facenet-pytorch) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision->facenet-pytorch) (1.3.0)\n","Installing collected packages: facenet-pytorch\n","Successfully installed facenet-pytorch-2.5.3\n"]}],"source":["!pip install facenet-pytorch"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":11143,"status":"ok","timestamp":1686229605726,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"8shCd--97T_s"},"outputs":[],"source":["# import dependencies\n","from IPython.display import display, Javascript\n","from IPython.display import Image as ipython_img\n","from matplotlib import pyplot as plt\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import time\n","import torch \n","from torchvision import transforms\n","from facenet_pytorch import InceptionResnetV1, fixed_image_standardization\n","from PIL import Image\n","import tensorflow as tf\n","import pickle"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PuTNGi9o7Wde"},"source":["# Import package"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1686229605727,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"Vsa0HhYI7X3n"},"outputs":[],"source":["import cv2\n","from facenet_pytorch import MTCNN\n","import torch\n","import os"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1686229605728,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"gAL6M4AT7Z6O","outputId":"60a72c59-517c-4252-9126-2d2dd1b81bec"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["#check type of device (cpu, gpu, tpu)\n","device =  torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ncx9FkrL73fS"},"source":["# Prepare data"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19779,"status":"ok","timestamp":1686229625497,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"jTwMBvuO7baW","outputId":"fcbe7afa-8304-4da5-9d66-a767f580bc2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/projects/ComputerVision/identifier_system_by_face\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","BASE_DIR = '/content/drive/MyDrive/projects/ComputerVision/identifier_system_by_face'\n","%cd '{BASE_DIR}'\n","TRAIN_DATASET_DIR = os.path.join(BASE_DIR, 'train_dataset')\n","TEST_DATASET_DIR = os.path.join(BASE_DIR, 'test_dataset')\n","IMG_FOLDER = 'img'\n","FACE_FOLDER = 'faces'\n","EMBEDDING_FOLDER = 'embeddings'"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"uZE3R1gNNJ0f"},"source":["# For face detection"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1686231327453,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"JvtTtWywNlQE"},"outputs":[],"source":["mtcnn = MTCNN(thresholds= [0.7, 0.7, 0.8] ,keep_all=True, device = device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NZnPuJ3hNO_P"},"outputs":[],"source":["def extract_face(box, img, frame_size, margin=20):\n","    face_size = 160\n","    img_size = frame_size\n","\n","    if box[0] > img_size[1] or box[2] > img_size[1]:\n","      print('Error face detection')\n","      return img, False\n","\n","    margin = [\n","        margin * (box[2] - box[0]) / (face_size - margin),\n","        margin * (box[3] - box[1]) / (face_size - margin),\n","    ]\n","    margin_box = [ #box[0] và box[1] là tọa độ của điểm góc trên cùng trái\n","        int(max(box[0] - margin[0] / 2, 0)), #nếu thêm vào margin bị ra khỏi rìa ảnh => đưa về điểm 0\n","        int(max(box[1] - margin[1] / 2, 0)),\n","        int(min(box[2] + margin[0] / 2, img_size[0])), #nếu thêm vào margin bị ra khỏi rìa ảnh => đưa về tọa độ của ảnh gốc\n","        int(min(box[3] + margin[1] / 2, img_size[1])),\n","    ] #tạo margin mới bao quanh box cũ\n","    try:\n","      margin_img = img[margin_box[1]:margin_box[3], margin_box[0]:margin_box[2], :]\n","      face = cv2.resize(margin_img,(face_size, face_size), interpolation=cv2.INTER_AREA)\n","    except:\n","      no_margin_img = img[box[1]:box[3], box[0]:box[2], :]\n","      face = cv2.resize(no_margin_img,(face_size, face_size), interpolation=cv2.INTER_AREA)\n","\n","\n","    #convert numpy array to image format\n","    #face = Img.fromarray(face)\n","    return face, True\n","\n","def save_img_to_file(img, img_path):\n","  cv2.imwrite(img_path, img)\n","\n","def transfrom_img(img):\n","  img = np.moveaxis(img, -1, 0)\n","  img = torch.from_numpy(img)\n","  return img/255\n","\n","def extract_and_save_faces(dataset_dir):\n","  for folder in os.listdir(dataset_dir):\n","    img_dir = os.path.join(dataset_dir, folder, IMG_FOLDER)\n","    face_dir = os.path.join(dataset_dir, folder, FACE_FOLDER)\n","    if os.path.exists(face_dir) != True:\n","      os.mkdir(face_dir)\n","    for img_file in os.listdir(img_dir):\n","      img_path = os.path.join(img_dir, img_file)\n","      input_img = cv2.imread(img_path)\n","      boxes, _ = mtcnn.detect(input_img)\n","      if boxes is not None:\n","          for idx, box in enumerate(boxes):\n","              bbox = list(map(int,box.tolist()))\n","              face, status = extract_face(bbox, input_img, input_img.shape)\n","              if status == True:\n","                face_path = os.path.join(face_dir, img_file)\n","                try:\n","                  save_img_to_file(face, face_path)\n","                except:\n","                  img_file = f'{img_file.split(\".\")[0]}.jpg'\n","                  face_path = os.path.join(face_dir, img_file)\n","                  save_img_to_file(face, face_path)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Xr7kSYwDMehQ"},"source":["# For pretrain model (pytorch) - Recognition"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20625,"status":"ok","timestamp":1686232963835,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"OL6SIPPQIXgQ","outputId":"c8c89614-70e9-4eee-f947-640d16c43d43"},"outputs":[{"data":{"text/plain":["InceptionResnetV1(\n","  (conv2d_1a): BasicConv2d(\n","    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","  )\n","  (conv2d_2a): BasicConv2d(\n","    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","  )\n","  (conv2d_2b): BasicConv2d(\n","    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","  )\n","  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2d_3b): BasicConv2d(\n","    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","  )\n","  (conv2d_4a): BasicConv2d(\n","    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","  )\n","  (conv2d_4b): BasicConv2d(\n","    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","  )\n","  (repeat_1): Sequential(\n","    (0): Block35(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (branch2): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (1): Block35(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (branch2): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (2): Block35(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (branch2): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (3): Block35(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (branch2): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (4): Block35(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (branch2): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","  )\n","  (mixed_6a): Mixed_6a(\n","    (branch0): BasicConv2d(\n","      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (branch1): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (2): BasicConv2d(\n","        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (repeat_2): Sequential(\n","    (0): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (1): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (2): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (3): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (4): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (5): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (6): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (7): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (8): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (9): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","  )\n","  (mixed_7a): Mixed_7a(\n","    (branch0): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (branch1): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (2): BasicConv2d(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (repeat_3): Sequential(\n","    (0): Block8(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (1): Block8(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (2): Block8(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (3): Block8(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (4): Block8(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","  )\n","  (block8): Block8(\n","    (branch0): BasicConv2d(\n","      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (branch1): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (2): BasicConv2d(\n","        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n","  (dropout): Dropout(p=0.6, inplace=False)\n","  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n","  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  (logits): Linear(in_features=512, out_features=8631, bias=True)\n",")"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["# Intialize embedding model\n","model = InceptionResnetV1(\n","    classify=False,\n","    pretrained=\"vggface2\"\n",").to(device)\n","\n","model.eval()"]},{"cell_type":"code","execution_count":71,"metadata":{"executionInfo":{"elapsed":528,"status":"ok","timestamp":1686232969939,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"xB8OVaRT7kJb"},"outputs":[],"source":["def embedding_and_save(dataset_dir):\n","  # Embedding face and save it\n","  for folder in os.listdir(dataset_dir):\n","    face_dir = os.path.join(dataset_dir, folder, FACE_FOLDER)\n","    embedding_dir = os.path.join(dataset_dir, folder, EMBEDDING_FOLDER)\n","    if os.path.exists(embedding_dir) != True:\n","      os.mkdir(embedding_dir)\n","    embeds = []\n","    for face_file in os.listdir(face_dir):\n","        face_path = os.path.join(face_dir, face_file)\n","        try:\n","            img = cv2.imread(face_path)\n","        except:\n","            continue\n","        with torch.no_grad():\n","            img = transfrom_img(img).to(device)\n","            img = img.unsqueeze(0)\n","            embed = model(img)\n","            embeds.append(embed) #1 anh, kich thuoc [1,512]\n","        if len(embeds) == 0:\n","            continue\n","    embedding = torch.cat(embeds).mean(0, keepdim=True) #dua ra trung binh cua 50 anh, kich thuoc [1,512]\n","    embedding_path = os.path.join(embedding_dir, f'{folder}.pth')\n","    torch.save(embedding, embedding_path)\n","\n","def prepare_data_for_training():\n","  print('PROCESSING TRAIN preparing data step')\n","  #training dataset\n","  extract_and_save_faces(TRAIN_DATASET_DIR)\n","  embedding_and_save(TRAIN_DATASET_DIR)\n","  print('DONE TRAIN preparing data step')\n","\n","def prepare_data_for_testing():\n","  print('PROCESSING TEST preparing data step')\n","  #testing dataset\n","  extract_and_save_faces(TEST_DATASET_DIR)\n","  embedding_and_save(TEST_DATASET_DIR)\n","  print('DONE TEST preparing data step')\n"]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11727,"status":"ok","timestamp":1686233458447,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"OKTUT1FINrCd","outputId":"e0459fcd-07e1-4e60-a8ea-5a87a80b22ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["PROCESSING TRAIN preparing data step\n","DONE TRAIN preparing data step\n","PROCESSING TEST preparing data step\n","DONE TEST preparing data step\n"]}],"source":["prepare_data_for_training()\n","prepare_data_for_testing()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"fgKx1GGFM1l2"},"source":["# For my own model (tensorflow) - Recognition"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eQddk41LdOos"},"source":["**Load my own model**"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4431,"status":"ok","timestamp":1686231602317,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"LsMT2QNvksVl","outputId":"d793ae0d-78e8-405f-e0c3-64eef2b05591"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow-addons==0.16.1 in /usr/local/lib/python3.10/dist-packages (0.16.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons==0.16.1) (4.0.0)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.5.0)\n"]}],"source":["!pip install tensorflow-addons==0.16.1"]},{"cell_type":"code","execution_count":58,"metadata":{"executionInfo":{"elapsed":2036,"status":"ok","timestamp":1686232059571,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"dhkbB7cAdT_3"},"outputs":[],"source":["MODEL_DIR = os.path.join(BASE_DIR, 'model')\n","model_name = 'face_recognition_triplot.h5'\n","model_path = os.path.join(MODEL_DIR, model_name)\n","model = tf.keras.models.load_model(model_path, compile=False)"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":558,"status":"ok","timestamp":1686231634975,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"TgME3DrQGQ76"},"outputs":[],"source":["def tf_embedding_and_save(dataset_dir):\n","  # Embedding face and save it\n","  for folder in os.listdir(dataset_dir):\n","    face_dir = os.path.join(dataset_dir, folder, FACE_FOLDER)\n","    embedding_dir = os.path.join(dataset_dir, folder, EMBEDDING_FOLDER)\n","    if os.path.exists(embedding_dir) != True:\n","      os.mkdir(embedding_dir)\n","    embeds = []\n","    for face_file in os.listdir(face_dir):\n","        face_path = os.path.join(face_dir, face_file)\n","        try:\n","            img = cv2.imread(face_path)\n","        except:\n","            continue\n","        img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n","        img = np.stack([img])\n","        embed = model.predict(img)\n","        embeds.append(embed) #1 anh, kich thuoc [1,512]\n","        if len(embeds) == 0:\n","            continue\n","    embedding = tf.concat(embeds, 0, name='concat')\n","    embedding = tf.reduce_mean(embedding, 0)\n","    embedding_path = os.path.join(embedding_dir, f'{folder}.pth')\n","    with open(embedding_path, 'wb') as file:\n","      # A new file will be created\n","      pickle.dump(embedding, file)\n","  \n","def tf_prepare_data_for_training():\n","  print('PROCESSING TRAIN preparing data step')\n","  #training dataset\n","  extract_and_save_faces(TRAIN_DATASET_DIR)\n","  tf_embedding_and_save(TRAIN_DATASET_DIR)\n","  print('DONE TRAIN preparing data step')\n","\n","def tf_prepare_data_for_testing():\n","  print('PROCESSING TEST preparing data step')\n","  #testing dataset\n","  extract_and_save_faces(TEST_DATASET_DIR)\n","  tf_embedding_and_save(TEST_DATASET_DIR)\n","  print('DONE TEST preparing data step')"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5820,"status":"ok","timestamp":1686231642168,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"O4Z4FXEK7llm","outputId":"067a033a-0741-4f2a-e7b5-df68380b4dee"},"outputs":[{"name":"stdout","output_type":"stream","text":["PROCESSING TRAIN preparing data step\n","1/1 [==============================] - 0s 231ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 31ms/step\n","DONE TRAIN preparing data step\n","PROCESSING TEST preparing data step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","DONE TEST preparing data step\n"]}],"source":["# Run preparing data\n","tf_prepare_data_for_training()\n","tf_prepare_data_for_testing()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"CvBoWiiV77UQ"},"source":["# Training model (from scratch)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":1539,"status":"ok","timestamp":1686230007732,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"I_l1xOMs79Zz"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Lambda, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications import VGG16\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1686212109104,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"xYF2ZD3K07my","outputId":"5e1a8fc6-460c-4651-c831-70d80f95761f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," dense_1 (Dense)             (None, 128)               3211392   \n","                                                                 \n"," lambda_1 (Lambda)           (None, 128)               0         \n","                                                                 \n","=================================================================\n","Total params: 17,926,080\n","Trainable params: 17,926,080\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["def _base_network():\n","  model = VGG16(include_top = True, weights = None)\n","  dense = Dense(128)(model.layers[-4].output)\n","  norm2 = Lambda(lambda x: tf.math.l2_normalize(x, axis = 1))(dense)\n","  model = Model(inputs = [model.input], outputs = [norm2])\n","  return model\n","\n","model = _base_network()\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3138,"status":"ok","timestamp":1686212114310,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"3Rs4Uqv11EFv","outputId":"b8e0d226-d46b-4e7b-c3e2-f494341ffa5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow-addons==0.16.1 in /usr/local/lib/python3.10/dist-packages (0.16.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons==0.16.1) (4.0.0)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.5.0)\n"]}],"source":["import tensorflow_addons as tfa\n","\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(0.001),\n","    loss=tfa.losses.TripletSemiHardLoss())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1891,"status":"ok","timestamp":1686212119203,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"3FlrrCAn1PzB","outputId":"6c07cf85-96b1-4729-b928-3d314bc1cde4"},"outputs":[{"data":{"text/plain":["<_BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None))>"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["X_train, testing_faces, y_train, testing_labels = load_dataset_for_recognition()\n","gen_train = tf.data.Dataset.from_tensor_slices((X_train, y_train)).repeat().shuffle(1024).batch(32)\n","gen_train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cIHiBbk81VWg"},"outputs":[],"source":["history = model.fit(\n","    gen_train,\n","    steps_per_epoch = 50,\n","    epochs=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6KjxAknlFT6C"},"outputs":[],"source":["MODEL_DIR = os.path.join(BASE_DIR, 'model')\n","if os.path.exists(MODEL_DIR) != True:\n","    os.mkdir(MODEL_DIR)\n","model_name = 'face_recognition_triplot.h5'\n","model_path = os.path.join(MODEL_DIR, model_name)\n","model.save(model_path)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZikOicVP7qB8"},"source":["# Evaluation - Recognition"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ai4gDTQE8ESV"},"source":["\n","\n","*   Đánh giá trong face recognition thì sẽ được tổng hợp từ 2 quá trình đánh giá:\n","\n","\n","1.   Đánh giá của bước face detection\n","2.   Đánh giá của bước face recognition\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":289,"status":"ok","timestamp":1686231649659,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"VgmFBeI60_3_"},"outputs":[],"source":["from sklearn.metrics import accuracy_score"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_eLk0UUFL0Wr"},"source":["# For pretrain (pytorch)"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686231578844,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"RZ55CALSL_OZ"},"outputs":[],"source":["def load_embedding_dataset_for_deploy():\n","  result = {'embedding': [], 'user_name': []}\n","  for user in os.listdir(TRAIN_DATASET_DIR):\n","      EMBEDDING_FILE = os.path.join(TRAIN_DATASET_DIR, user, EMBEDDING_FOLDER, f'{user}.pth')\n","      embedding = torch.load(EMBEDDING_FILE)\n","      user_name = str(user)\n","      result['embedding'].append(embedding)\n","      result['user_name'].append(user_name)\n","  return result\n","\n","def inference(face, model, embedding_dataset, threshold=0.8):\n","  local_embeds = torch.cat(embedding_dataset['embedding'])\n","  names = embedding_dataset['user_name']\n","  face = transfrom_img(face).to(device)\n","  face = face.unsqueeze(0)\n","  embed = model(face)\n","  norm_diff = embed - local_embeds\n","  norm_square = torch.pow(norm_diff, 2)\n","  norm_score = torch.sum(norm_square, dim=1) #(1,n)\n","  #norm_score = torch.sqrt(norm_score)\n","  embed_idx = torch.argmin(norm_score)\n","  min_dist = norm_score[embed_idx]\n","  if min_dist > threshold:\n","      return -1, -1\n","  else:\n","      return names[embed_idx], min_dist\n","\n","def load_dataset_for_recognition():\n","  training_faces, testing_faces, training_labels, testing_labels = [], [], [], []\n","  for user in os.listdir(TRAIN_DATASET_DIR):\n","    faces_folder = os.path.join(TRAIN_DATASET_DIR, user, FACE_FOLDER)\n","    for face in os.listdir(faces_folder):\n","      face_path = os.path.join(faces_folder, face)\n","      face = cv2.imread(face_path)\n","      #for trainign model - not pretrained model\n","      #face = cv2.resize(face, (224, 224), interpolation=cv2.INTER_AREA)\n","      training_faces.append(face)\n","      training_labels.append(user)\n","  \n","  for user in os.listdir(TEST_DATASET_DIR):\n","    faces_folder = os.path.join(TEST_DATASET_DIR, user, FACE_FOLDER)\n","    for face in os.listdir(faces_folder):\n","      face_path = os.path.join(faces_folder, face)\n","      face = cv2.imread(face_path)\n","      #for trainign model - not pretrained model\n","      #face = cv2.resize(face, (224, 224), interpolation=cv2.INTER_AREA)\n","      testing_faces.append(face)\n","      testing_labels.append(user)\n","  return training_faces, testing_faces, training_labels, testing_labels\n","\n","def recognition_evaluation(model):\n","  embedding_dataset = load_embedding_dataset_for_deploy()\n","  training_faces, testing_faces, training_labels, testing_labels = load_dataset_for_recognition()\n","  predicts = []\n","  for face in testing_faces:\n","    user, score = inference(face, model, embedding_dataset)\n","    if user == -1:\n","      user = 'unknown'\n","    else:\n","      # Using cv2.putText() method to display score\n","      score = torch.round(score, decimals=4)\n","    predicts.append(user)\n","  acc = accuracy_score(testing_labels, predicts)\n","  print('accuracy: ', acc)"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1318,"status":"ok","timestamp":1686232983556,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"v5T6_9OLMTo5","outputId":"1b2ed9f0-314a-4cf0-f415-c3d046d83ef6"},"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy:  0.8846153846153846\n"]}],"source":["#Evaluation execute\n","recognition_evaluation(model)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DnUNfvZLMEf2"},"source":["# For my own model (tensorflow)"]},{"cell_type":"code","execution_count":67,"metadata":{"executionInfo":{"elapsed":366,"status":"ok","timestamp":1686232799945,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"gQT7fa8E7wWj"},"outputs":[],"source":["def tf_load_embedding_dataset_for_deploy():\n","  result = {'embedding': [], 'user_name': []}\n","  for user in os.listdir(TRAIN_DATASET_DIR):\n","      EMBEDDING_FILE = os.path.join(TRAIN_DATASET_DIR, user, EMBEDDING_FOLDER, f'{user}.pth')\n","      with open(EMBEDDING_FILE, 'rb') as file:\n","        # Call load method to deserialze\n","        embedding = pickle.load(file)\n","      user_name = str(user)\n","      result['embedding'].append(embedding)\n","      result['user_name'].append(user_name)\n","  return result\n","\n","def tf_load_dataset_for_recognition():\n","  training_faces, testing_faces, training_labels, testing_labels = [], [], [], []\n","  for user in os.listdir(TRAIN_DATASET_DIR):\n","    faces_folder = os.path.join(TRAIN_DATASET_DIR, user, FACE_FOLDER)\n","    for face in os.listdir(faces_folder):\n","      face_path = os.path.join(faces_folder, face)\n","      face = cv2.imread(face_path)\n","      #for trainign model - not pretrained model\n","      face = cv2.resize(face, (224, 224), interpolation=cv2.INTER_AREA)\n","      training_faces.append(face)\n","      training_labels.append(user)\n","  \n","  for user in os.listdir(TEST_DATASET_DIR):\n","    faces_folder = os.path.join(TEST_DATASET_DIR, user, FACE_FOLDER)\n","    for face in os.listdir(faces_folder):\n","      face_path = os.path.join(faces_folder, face)\n","      face = cv2.imread(face_path)\n","      #for trainign model - not pretrained model\n","      face = cv2.resize(face, (224, 224), interpolation=cv2.INTER_AREA)\n","      testing_faces.append(face)\n","      testing_labels.append(user)\n","  return training_faces, testing_faces, training_labels, testing_labels\n","\n","def tf_inference(face, model, embedding_dataset, threshold=0.8, verbose=1):\n","  local_embeds = embedding_dataset['embedding']\n","  names = embedding_dataset['user_name']\n","  #print(face.shape, local_embeds.shape)\n","  face = cv2.resize(face, (224, 224), interpolation=cv2.INTER_AREA)\n","  face = np.stack([face])\n","  embed = model.predict(face, verbose=verbose)\n","  norm_diff = embed - local_embeds\n","  norm_square = np.power(norm_diff, 2)\n","  norm_score = np.sum(norm_square, axis=1) #(1,n)\n","  #norm_score = torch.sqrt(norm_score)\n","  embed_idx = np.argmin(norm_score)\n","  min_dist = norm_score[embed_idx]\n","  if min_dist > threshold:\n","      return -1, -1\n","  else:\n","      return names[embed_idx], min_dist\n","\n","def tf_recognition_evaluation(model):\n","  embedding_dataset = tf_load_embedding_dataset_for_deploy()\n","  training_faces, testing_faces, training_labels, testing_labels = tf_load_dataset_for_recognition()\n","  predicts = []\n","  for face in testing_faces:\n","    user, score = tf_inference(face, model, embedding_dataset)\n","    if user == -1:\n","      user = 'unknown'\n","    else:\n","      # Using cv2.putText() method to display score\n","      #score = torch.round(score, decimals=4)\n","      pass\n","    predicts.append(user)\n","  print(testing_labels)\n","  print(predicts)\n","  acc = accuracy_score(testing_labels, predicts)\n","  print('accuracy: ', acc)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58131,"status":"ok","timestamp":1686231799693,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"2h6RLdxMH2uk","outputId":"58e25923-d21f-4cb2-d392-f3f46d4448af"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","['ronaldo', 'ronaldo', 'ronaldo', 'ronaldo', 'ronaldo', 'ronaldo', 'ronaldo', 'ronaldo', 'ronaldo', 'ronaldo', 'ronaldo', 'ronaldo', 'ronaldo', 'messi', 'messi', 'messi', 'messi', 'messi', 'messi', 'messi', 'messi', 'messi', 'messi', 'messi', 'messi', 'messi']\n","['ronaldo', 'ronaldo', 'messi', 'ronaldo', 'ronaldo', 'ronaldo', 'ronaldo', 'ronaldo', 'ronaldo', 'ronaldo', 'ronaldo', 'messi', 'ronaldo', 'messi', 'messi', 'messi', 'messi', 'messi', 'messi', 'messi', 'messi', 'messi', 'messi', 'messi', 'messi', 'messi']\n","accuracy:  0.9230769230769231\n"]}],"source":["#Evaluation execute\n","tf_recognition_evaluation(model)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"OWAvOuT4MYLf"},"source":["# Deploy"]},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1mTWKFuFZoNyXvbA0tnODziEcmrZDvQlK"},"executionInfo":{"elapsed":11926,"status":"ok","timestamp":1686232242476,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"rdEvwkx-7yK0","outputId":"a0d8b86c-c7ee-48a2-81d5-db8fa8f7a92a"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["# Deploy with query method (compute simalarity between two embedding - input and my own dataset)\n","embedding_dataset = tf_load_embedding_dataset_for_deploy()\n","\n","for user in os.listdir(TEST_DATASET_DIR):\n","  user_dir = os.path.join(TEST_DATASET_DIR, user, IMG_FOLDER)\n","  for img_file in os.listdir(user_dir):\n","    img_path = os.path.join(user_dir, img_file)\n","    img = cv2.imread(img_path)\n","    boxes, probs = mtcnn.detect(img)\n","    if boxes is not None:\n","      for box, prob in zip(boxes, probs):\n","        bbox = list(map(int,box.tolist()))\n","        face, status = extract_face(bbox, img, img.shape)\n","        if status == True:\n","          user, score = tf_inference(face, model, embedding_dataset)\n","          if user == -1:\n","            user = 'unknown'\n","            img = cv2.putText(img, f'{user}', (bbox[0],bbox[1]), cv2.FONT_HERSHEY_SIMPLEX, \n","                        0.3, (0, 0, 255), 1, cv2.LINE_AA)\n","            img = cv2.rectangle(img,(bbox[0],bbox[1]),(bbox[2],bbox[3]),(0,0,255),1)\n","          else:\n","            print(img_file)\n","            # Using cv2.putText() method to display score\n","            #score = torch.round(score, decimals=4)\n","            img = cv2.putText(img, f'{user}: {score}', (bbox[0],bbox[1]), cv2.FONT_HERSHEY_SIMPLEX, \n","                        0.3, (0, 0, 255), 1, cv2.LINE_AA)\n","            img = cv2.rectangle(img,(bbox[0],bbox[1]),(bbox[2],bbox[3]),(0,0,255),1)\n","        else:\n","          print('face detection is error')\n","    #image show in ipython\n","    plt.axis(\"off\")\n","    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","    plt.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SuEGIks0RhLu"},"source":["# Deploy real-time on camera"]},{"cell_type":"code","execution_count":63,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1686232296514,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"9hi5zFhzRoEf"},"outputs":[],"source":["# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img\n","\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n","def bbox_to_bytes(bbox_array):\n","  \"\"\"\n","  Params:\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n","  Returns:\n","        bytes: Base64 image byte string\n","  \"\"\"\n","  # convert array into PIL image\n","  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n","  iobuf = io.BytesIO()\n","  # format bbox into png for return\n","  bbox_PIL.save(iobuf, format='png')\n","  # format return string\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","\n","  return bbox_bytes"]},{"cell_type":"code","execution_count":64,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686232298352,"user":{"displayName":"Hung Dang","userId":"15478570637406264472"},"user_tz":-420},"id":"qzLdWG18RsiQ"},"outputs":[],"source":["# JavaScript to properly create our live video stream using our webcam as input\n","def video_stream():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)\n","  \n","def video_frame(label, bbox):\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","  return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CkKAsxexrbQy"},"outputs":[],"source":["#load_data_for_query\n","embedding_dataset = load_embedding_dataset_for_deploy()\n","\n","# start streaming video from webcam\n","# infer with mtcnn on colab (using camera from latop)\n","video_stream()\n","# label for video\n","label_html = 'Capturing...'\n","# initialze bounding box to empty\n","bbox = ''\n","count = 0 \n","while True:\n","    js_reply = video_frame(label_html, bbox)\n","    if not js_reply:\n","        break\n","\n","    # convert JS response to OpenCV Image\n","    img = js_to_image(js_reply[\"img\"])\n","\n","    # create transparent overlay for bounding box\n","    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n","\n","    # grayscale image for face detection\n","    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","  \n","    # get face region coordinates\n","    bboxes, _ = mtcnn.detect(img)\n","    #bbox_array = img\n","    # get face bounding box for overlay\n","    if bboxes is not None:\n","      for box in bboxes:\n","          bbox = list(map(int,box.tolist()))\n","          \n","          face, status = extract_face(bbox, img, img.shape)\n","          if status == True:\n","            user, score = inference(face, model, embedding_dataset)\n","            #user, score = tf_inference(face, model, embedding_dataset, verbose=0)\n","            if user == -1:\n","              user = 'unknown'\n","              bbox_array = cv2.putText(bbox_array, f'{user}', (bbox[0],bbox[1]), cv2.FONT_HERSHEY_SIMPLEX, \n","                          0.3, (0, 0, 255), 1, cv2.LINE_AA)\n","              bbox_array = cv2.rectangle(bbox_array,(bbox[0],bbox[1]),(bbox[2],bbox[3]),(0,0,255),1)\n","            else:\n","              # Using cv2.putText() method to display score\n","              #score = torch.round(score, decimals=4)\n","              bbox_array = cv2.putText(bbox_array, f'{user}: {score}', (bbox[0],bbox[1]), cv2.FONT_HERSHEY_SIMPLEX, \n","                          0.3, (0, 0, 255), 1, cv2.LINE_AA)\n","              bbox_array = cv2.rectangle(bbox_array,(bbox[0],bbox[1]),(bbox[2],bbox[3]),(0,0,255),1)\n","            #bbox_array = cv2.rectangle(bbox_array,(bbox[0],bbox[1]),(bbox[2],bbox[3]),(0,0,255),6)\n","          else:\n","            print('face detection is error')\n","    #for (x,y,w,h) in faces:\n","      #bbox_array = cv2.rectangle(bbox_array,(x,y),(x+w,y+h),(255,0,0),2)\n","    \n","    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n","    # convert overlay of bbox into bytes\n","    bbox_bytes = bbox_to_bytes(bbox_array)\n","    # update bbox so next frame gets new overlay\n","    bbox = bbox_bytes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ghl7oG0oTDT6"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPPXwPPVG7yqvcxoMKRivHA","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
